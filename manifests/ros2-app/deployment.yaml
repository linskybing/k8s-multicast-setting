apiVersion: apps/v1
kind: Deployment
metadata:
  name: ros2-talker
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ros2-talker
  template:
    metadata:
      labels:
        app: ros2-talker
      annotations:
        k8s.v1.cni.cncf.io/networks: macvlan-conf
    spec:
      containers:
      - name: ros2-talker
        image: ros:humble-ros-base
        command: ["/bin/bash", "-c"]
        # Use 'ros2 topic pub' which is available in ros-base. 
        # We add a sleep loop to keep the container alive if ros2 fails, for debugging.
        args: 
        - |
          source /opt/ros/humble/setup.bash && \
          echo "Starting Talker..." && \
          ros2 topic pub /chatter std_msgs/msg/String "data: 'Hello Multicast'" -r 1
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
            # nvidia.com/gpu: 1 # Uncomment if GPU is needed for this node
        env:
        - name: ROS_DOMAIN_ID
          value: "0"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ros2-listener
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ros2-listener
  template:
    metadata:
      labels:
        app: ros2-listener
      annotations:
        k8s.v1.cni.cncf.io/networks: macvlan-conf
    spec:
      containers:
      - name: ros2-listener
        image: ros:humble-ros-base
        command: ["/bin/bash", "-c"]
        # Use 'ros2 topic echo' which is available in ros-base.
        args: 
        - |
          source /opt/ros/humble/setup.bash && \
          echo "Starting Listener..." && \
          ros2 topic echo /chatter
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
            # nvidia.com/gpu: 1 # Uncomment if GPU is needed for this node
        env:
        - name: ROS_DOMAIN_ID
          value: "0"