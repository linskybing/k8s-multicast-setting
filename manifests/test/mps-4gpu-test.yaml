# ==========================================
# 測試 1: 基準組 (4 張卡同時全速跑)
# ==========================================
apiVersion: batch/v1
kind: Job
metadata:
  name: mps-benchmark-baseline-4gpu
spec:
  completions: 4
  parallelism: 4
  template:
    metadata:
      labels:
        app: mps-baseline-4gpu
    spec:
      restartPolicy: Never
      nodeSelector:
        kubernetes.io/hostname: gpu1
      containers:
      - name: cuda-app
        image: nvidia/cuda:12.4.1-devel-ubuntu22.04
        resources:
          limits:
            nvidia.com/gpu-0: 1
        command: ["/bin/bash", "-c"]
        args:
          - |
            cat <<EOF > benchmark.cu
            #include <cuda_runtime.h>
            #include <iostream>
            #include <cmath>
            #include <iomanip>
            #define N 8192 

            __global__ void heavy_kernel(float *a, int n) {
                int idx = blockIdx.x * blockDim.x + threadIdx.x;
                if (idx < n * n) {
                    float val = 0.0f;
                    for (int i = 0; i < 2000; ++i) {
                        val += sinf(idx * i) * cosf(idx * i);
                    }
                    a[idx] = val;
                }
            }

            int main() {
                int devId;
                cudaGetDevice(&devId);
                cudaDeviceProp prop;
                cudaGetDeviceProperties(&prop, devId);
                std::cout << "Running on GPU: " << prop.name 
                          << " [BusID: " << std::hex << prop.pciBusID << std::dec << "]" << std::endl;

                float *d_a;
                size_t size = N * N * sizeof(float);
                cudaMalloc(&d_a, size);
                cudaEvent_t start, stop;
                cudaEventCreate(&start);
                cudaEventCreate(&stop);

                std::cout << "Starting 4-GPU Baseline (100%)..." << std::endl;
                cudaEventRecord(start);
                
                int threads = 256;
                int blocks = (N * N + threads - 1) / threads;
                heavy_kernel<<<blocks, threads>>>(d_a, N);
                
                cudaEventRecord(stop);
                cudaEventSynchronize(stop);
                float milliseconds = 0;
                cudaEventElapsedTime(&milliseconds, start, stop);

                std::cout << "Time: " << milliseconds << " ms" << std::endl;
                cudaFree(d_a);
                return 0;
            }
            EOF
            nvcc benchmark.cu -o benchmark -O3 
            ./benchmark
---
apiVersion: batch/v1
kind: Job
metadata:
  name: mps-benchmark-limited-4gpu
spec:
  completions: 4
  parallelism: 4
  template:
    metadata:
      labels:
        app: mps-limited-4gpu
    spec:
      restartPolicy: Never
      nodeSelector:
        kubernetes.io/hostname: gpu1
      containers:
      - name: cuda-app
        image: nvidia/cuda:12.4.1-devel-ubuntu22.04
        env:
          - name: CUDA_MPS_ACTIVE_THREAD_PERCENTAGE
            value: "20"
          - name: CUDA_MPS_PINNED_DEVICE_MEM_LIMIT
            value: "0:6400M"
        resources:
          limits:
            nvidia.com/gpu-0: 1
        command: ["/bin/bash", "-c"]
        args:
          - |
            cat <<EOF > benchmark.cu
            #include <cuda_runtime.h>
            #include <iostream>
            #include <cmath>
            #include <iomanip>
            #define N 8192 

            __global__ void heavy_kernel(float *a, int n) {
                int idx = blockIdx.x * blockDim.x + threadIdx.x;
                if (idx < n * n) {
                    float val = 0.0f;
                    for (int i = 0; i < 2000; ++i) {
                        val += sinf(idx * i) * cosf(idx * i);
                    }
                    a[idx] = val;
                }
            }

            int main() {
                int devId;
                cudaGetDevice(&devId);
                cudaDeviceProp prop;
                cudaGetDeviceProperties(&prop, devId);
                std::cout << "Running on GPU: " << prop.name 
                          << " [BusID: " << std::hex << prop.pciBusID << std::dec << "]" << std::endl;

                float *d_a;
                size_t size = N * N * sizeof(float);
                cudaMalloc(&d_a, size);
                cudaEvent_t start, stop;
                cudaEventCreate(&start);
                cudaEventCreate(&stop);

                std::cout << "Starting 4-GPU Limited (20%)..." << std::endl;
                cudaEventRecord(start);
                
                int threads = 256;
                int blocks = (N * N + threads - 1) / threads;
                heavy_kernel<<<blocks, threads>>>(d_a, N);
                
                cudaEventRecord(stop);
                cudaEventSynchronize(stop);
                float milliseconds = 0;
                cudaEventElapsedTime(&milliseconds, start, stop);

                std::cout << "Time: " << milliseconds << " ms" << std::endl;
                cudaFree(d_a);
                return 0;
            }
            EOF
            nvcc benchmark.cu -o benchmark -O3 
            ./benchmark