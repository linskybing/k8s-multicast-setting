apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: mps-soft-mig-enforcement
  annotations:
    policies.kyverno.io/title: Enforce NVIDIA MPS Limits (Soft-MIG)
    policies.kyverno.io/category: GPU Security
    policies.kyverno.io/description: >-
      This policy implements a "Soft-MIG" architecture for consumer GPUs.
      It intercepts Pods requesting NVIDIA GPUs and injects MPS environment variables
      to strictly limit VRAM and Compute threads based on Pod annotations.
      It also enforces a read-only root filesystem to prevent tampering.
spec:
  rules:
    # Rule 1: Set Default "Free Tier" Limits if Annotations are Missing
    - name: set-default-mps-limits
      match:
        any:
        - resources:
            kinds:
            - Pod
      preconditions:
        any:
        - key: "{{ request.object.spec.containers[].resources.limits.\"nvidia.com/gpu\" || '' }}"
          operator: AnyIn
          value: ["*"]
        - key: "{{ request.object.spec.containers[].resources.limits.\"nvidia.com/gpu.shared\" || '' }}"
          operator: AnyIn
          value: ["*"]
      mutate:
        patchStrategicMerge:
          metadata:
            annotations:
              +(mps.nvidia.com/vram): "1280M" # Default 1.25GB
              +(mps.nvidia.com/threads): "4"  # Default 4%

    # Rule 2: Inject MPS Environment Variables based on Annotations
    - name: inject-mps-env-vars
      match:
        any:
        - resources:
            kinds:
            - Pod
      preconditions:
        any:
        - key: "{{ request.object.spec.containers[].resources.limits.\"nvidia.com/gpu\" || '' }}"
          operator: AnyIn
          value: ["*"]
        - key: "{{ request.object.spec.containers[].resources.limits.\"nvidia.com/gpu.shared\" || '' }}"
          operator: AnyIn
          value: ["*"]
      mutate:
        foreach:
        - list: "request.object.spec.containers"
          patchStrategicMerge:
            spec:
              containers:
              - name: "{{ element.name }}"
                env:
                # VRAM Limit: Format "0=4G" or "0=1280M"
                # The '0=' prefix targets GPU 0 (MPS sees the physical GPU as 0)
                - name: CUDA_MPS_PINNED_DEVICE_MEM_LIMIT
                  value: "0={{ request.object.metadata.annotations.\"mps.nvidia.com/vram\" }}"
                # Thread Limit: Percentage (0-100)
                - name: CUDA_MPS_ACTIVE_THREAD_PERCENTAGE
                  value: "{{ request.object.metadata.annotations.\"mps.nvidia.com/threads\" }}"
                # Ensure MPS Pipe Directory is set (Standard location)
                - name: CUDA_MPS_PIPE_DIRECTORY
                  value: "/tmp/nvidia-mps"
                - name: CUDA_MPS_LOG_DIRECTORY
                  value: "/tmp/nvidia-mps/log"
                volumeMounts:
                - name: nvidia-mps
                  mountPath: /tmp/nvidia-mps
                - name: nvidia-mps-shm
                  mountPath: /dev/shm

    # Rule 3: Security Hardening - Enforce Read-Only Root Filesystem
    - name: enforce-readonly-root
      match:
        any:
        - resources:
            kinds:
            - Pod
      preconditions:
        any:
        - key: "{{ request.object.spec.containers[].resources.limits.\"nvidia.com/gpu\" || '' }}"
          operator: AnyIn
          value: ["*"]
        - key: "{{ request.object.spec.containers[].resources.limits.\"nvidia.com/gpu.shared\" || '' }}"
          operator: AnyIn
          value: ["*"]
      mutate:
        foreach:
        - list: "request.object.spec.containers"
          patchStrategicMerge:
            spec:
              containers:
              - name: "{{ element.name }}"
                securityContext:
                  readOnlyRootFilesystem: true
                  # Allow writing to /tmp and /run/nvidia/mps if needed, usually handled by volume mounts
                  # Note: User must ensure volume mounts exist for writable areas

    # Rule 4: Inject MPS Volumes (HostPath)
    - name: inject-mps-volumes
      match:
        any:
        - resources:
            kinds:
            - Pod
      preconditions:
        any:
        - key: "{{ request.object.spec.containers[].resources.limits.\"nvidia.com/gpu\" || '' }}"
          operator: AnyIn
          value: ["*"]
        - key: "{{ request.object.spec.containers[].resources.limits.\"nvidia.com/gpu.shared\" || '' }}"
          operator: AnyIn
          value: ["*"]
      mutate:
        patchStrategicMerge:
          spec:
            volumes:
            - name: nvidia-mps
              hostPath:
                path: /run/nvidia/mps
                type: Directory
            - name: nvidia-mps-shm
              hostPath:
                path: /dev/shm
                type: Directory
